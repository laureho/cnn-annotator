{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Annotation with Napari\n",
    "\n",
    "### Welcome! \n",
    "\n",
    "This notebook allows you to import your raw microscopy data into [_Napari_](https://napari.org/ \"Napari: a fast, interactive, multi-dimensional image viewer for Python\"), a fast, interactive, multi-dimensional image viewer for Python. Follow the step-wise instructions to annotate your large, multi-dimensional images and extract single-cell image patches corresponding to different states of the cell cycle. \n",
    "\n",
    "This is a preview of the *napari* interface for image annotations:\n",
    "![image](../assets/napari_annotator.png)\n",
    "\n",
    "\n",
    "### Running Instructions:\n",
    "\n",
    "1. To run this notebook, go to ```Kernel``` and click on ```Restart & Run All```. Alternatively, for a shortcut, click on the ```‚è© ``` in the top dashboard. It's the icon right next to the ```Run ‚ñ∂Ô∏è```, ``` ‚èπÔ∏è```, ``` üîÅ``` and the ```Code``` dropdown window. This will restart the notebook & run all of its cells.\n",
    "\n",
    "2. Calling the last cell will start a separate Python window with the *napari* widget. Please allow a few seconds to load the graphical user interface (GUI) to load. You should see your movie loaded on the screen, such as here:\n",
    "\n",
    "\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "- Make sure you have the latest version of *napari* installed in your virtual environment. If in doubt, run ```pip install napari -U``` for installing the upgrade. \n",
    "- Do not forget to export your annotation zip file before terminating the session. The annotations will not be autosaved nor exported automatically, so failing to export your annotations will result in your work being lost!\n",
    "- Keep in mind that not all of your annotations have to be stored in a single zip file - you can create as many annotations as you'd like and spread out your annotated dataset across multiple zip files.\n",
    "\n",
    "---\n",
    "\n",
    "## Annotating the Single-Cell Image Patches:\n",
    "\n",
    "To train a neural network to automatically and accurately classify previously unseen single-cell images, we need to manually annotate a handful of such image patches with a label. This is because the learning approach we use to train such a network is *supervised* (by a human annotator) - this means that for the learning algorithm to master the patterns representative for each class, we need to provide some of the images with the correct answer, often referred to as the *'ground truth'*. This allows the network to make high-fidelity predictions about previously unseen images.\n",
    "\n",
    "In this section, a random sample of labeled images needs to be provided by annotating any microscopy movie of choice. The rule of thumb is that the more examples you can generate the better. We recommend to label at least **500 instances per each class** for reasonably accurate training. Using the guide below, please annotate each image with one of the five labels provided.\n",
    "\n",
    "Here are some examples of cells and their corresponding labels:\n",
    "![image](../assets/cell_cycle_states.png)\n",
    "\n",
    "\n",
    "### Annotation Instructions:\n",
    "\n",
    "1. Annotate your movie by clicking on the individual instances of the labels you wish to annotate. Although there is no sub-pixels targetting accuracy required at this stage, please aim to click at the centre of each cell / nucleus to allow the image patches to be cropped around those coordinates properly. The default labels is *interphase*.\n",
    "\n",
    "2. Change the labels for which you wish to annotate at the bottom left corner of the GUI by choosing the appropriate label from the dropdown menu. There should be 5 labels available: *interphase (default), prometaphase, metaphase, anaphase and apoptosis*. You can swiftly change between the class labels by pressing ```.``` or ```,``` keyboard key for the next or previous label, respectively.\n",
    "\n",
    "3. When done annotating one image, you can move to the next image by clicking on the ```right arrow``` or ```left arrow``` on the slider at the bottom of the GUI. Alternatively, you can select the image layer in the left panel and use the keyboard left/right keys or Ctrl-scroll to browse.\n",
    "\n",
    "4. To erase a mislabelled point from the annotations list, choose the ```Delete point``` button at the top left corner of the GUI, or press the `backspace` key. This will only delete the latest point. You can delete many mislabelled points by clicking on the ```Multi-point selection``` button (or by pressing the `S`-key), holding `shift` as you select individual cells, then using the ```Delete point``` button (or `backspace` key). \n",
    "\n",
    "5. When done annotating, export the annotation file by clicking the ```Export``` button at the very bottom right corner of the GUI. **Do not forget to export your annotations before terminating the session. The annotations will not be autosaved nor exported automatically.** \n",
    "\n",
    "6. *Have you exported the annotations?* Close the GUI by clicking on the red ```X``` to quit the python GUI completely. *Optional:* If using OS X, choose to 'Force quit' the napari window for completeness. Doing so will cause this notebook's kernel to die. This outcome is fine as this notebook task is finished.\n",
    "\n",
    "---\n",
    "\n",
    "**Happy annotating!**\n",
    "\n",
    "*Your [CellX](http://lowe.cs.ucl.ac.uk/cellx.html \"Lowe Lab @ UCL\") team*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import some useful libraries:\n",
    "\n",
    "We first need to load some libraries of code that will help with the data processing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import napari\n",
    "import numpy as np\n",
    "\n",
    "from magicgui import magicgui\n",
    "from skimage.io import imread\n",
    "from skimage.io import imsave\n",
    "from skimage.io import imshow\n",
    "\n",
    "from pathlib import Path\n",
    "from napari.layers import Image\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide the directory for the movie you wish to annotate:\n",
    "\n",
    "In this example, we provide an example 50-frame long crop (600 x 450 pixels) of a time-lapse microscopy movie ```MDCK_H2B_GFP_movie.tif``` of MDCK cells expressing an *H2B-GFP* fluorescent tag, which visualises the nuclei of the individual cells. This movie has dimensions (*i.e.* shape) of ```(50, 450, 600)```. When loading your own movie, make sure it is saved as a ```tif``` file and provide its absolute path.\n",
    "\n",
    "Unit conversion for example data: *1 ¬µm = 3 pixels, 1 frame = 4 minutes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/MDCK_H2B_GFP_movie.tif\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/MDCK_H2B_GFP_movie.tif\"\n",
    "print (filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the image data from the movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = imread(filename)\n",
    "metadata = {\"filename\": filename}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cell cycle states which you'd like your CNN to categorise:\n",
    "\n",
    "Create an object with enumerated classes which you want to classify. In this particular example, we provide 4 classes of actively dividing cells (*i.e. **interphase** pooled for G1-, S- and G2-phases & **pro(meta)phase, metaphase & ana(telo)phase** for specific phases of cell division*) and 1 class for ceasing cells (*i.e. **apoptosis***). \n",
    "\n",
    "To familiarise yourself with the typical cell morphologies & chromatin condensation of an actively dividing cell, please see the example images below:\n",
    "\n",
    "![image](../assets/cell_cycle_states.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum.unique\n",
    "class CellState(enum.Enum):\n",
    "    Interphase = 0\n",
    "    Prometaphase = 1\n",
    "    Metaphase = 2\n",
    "    Anaphase = 3\n",
    "    Apoptosis = 4\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the colours to individual labelled states:\n",
    "\n",
    "The default settings will follow the ```matplotlib``` standard colour library with {\"blue\", \"orange\", \"green\", \"red\", \"purple\"}. \n",
    "\n",
    "*Note:* When changing the default setting or defining new colour palettes, please specify the [HEX code](https://www.color-hex.com/ \"HEX Color Codes\") for new colours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_CYCLE = [\n",
    "    '#1f77b4', # blue\n",
    "    '#ff7f0e', # orange\n",
    "    '#2ca02c', # green\n",
    "    '#d62728', # red\n",
    "    '#9467bd', # purple\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function crops an image patch around the labelled points:\n",
    "\n",
    "Default setting will crop a 64 x 64 pixel square image patch with the labelled point at the centre of the patch, i.e. 32 pixels up, 32 pixels down, 32 pixels left & 32 pixels right from the labelled coordinates. Please only alter with care.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_patch(layers, coords, shape=64):\n",
    "    \"\"\" Get an image patch from the image layer data. \"\"\"\n",
    "    \n",
    "    flagged = False\n",
    "    square = shape // 2\n",
    "\n",
    "    patches = []\n",
    "    \n",
    "    for layer in layers:\n",
    "        \n",
    "        # Read the image from layers:\n",
    "        frame, y_coo, x_coo = [int(coo) for coo in coords]\n",
    "        image = layer.data[frame]\n",
    "        im_h, im_w = image.shape\n",
    "        edge_dist = [y_coo, im_h - y_coo, x_coo, im_w - x_coo]\n",
    "        \n",
    "        # Check if padding is needed:\n",
    "        if any([item < square for item in edge_dist]):\n",
    "            pad_width = int(square - min(edge_dist))\n",
    "            image = np.pad(array=image, pad_width=pad_width, mode='constant')\n",
    "            y_coo = y_coo + pad_width\n",
    "            x_coo = x_coo + pad_width\n",
    "            flagged = True\n",
    "\n",
    "        # Slice the patch from the image:\n",
    "        patch = image[y_coo-square : y_coo+square, x_coo-square : x_coo+square].astype(np.uint8)\n",
    "        patches.append(patch) \n",
    "        \n",
    "    # Check if all patches are of specified shape:\n",
    "    #if not all([patch.shape == (shape, shape) for patch in patches[0]]):\n",
    "    #    raise ValueError(f\"Image patches don't have correct shape: {[patch.shape for patch in patches[0]]}\")\n",
    "    \n",
    "    return np.stack(patches, axis=-1), flagged\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The annotator function:\n",
    "\n",
    "For those users more experienced at Python, you can read the code the below & possibly add more ```key_bindings``` functions for an even smoother annotation in *napari*: visit this [guide](https://napari.org/docs/0.3.8/_modules/napari/utils/key_bindings.html \"Source code for napari.utils.key_bindings\"). Otherwise, no manipulation is encouraged at this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotator(viewer):\n",
    "    \n",
    "    SESSION_TIME = datetime.now().strftime(\"%m-%d-%Y--%H-%M-%S\")\n",
    "    SESSION_NAME = f\"annotation_{SESSION_TIME}\"\n",
    "    \n",
    "    # add an empty points layer, with the same dimensions as the image data\n",
    "    points_layer = viewer.add_points(\n",
    "        name=\"Annotation\", \n",
    "        properties={'State': [s.name for s in CellState]}, \n",
    "        ndim=data.ndim\n",
    "    )\n",
    "\n",
    "    points_layer.mode = 'add'\n",
    "    points_layer.face_color = 'State'\n",
    "    points_layer.face_color_cycle = COLOR_CYCLE\n",
    "    points_layer.face_color_mode = 'cycle'\n",
    "\n",
    "    \n",
    "    @magicgui(\n",
    "        call_button=\"Export\",\n",
    "        layout=\"horizontal\",\n",
    "        filename={\"label\": \"Export path:\"},\n",
    "    )\n",
    "    \n",
    "    def cnn_annotation_widget(\n",
    "        filename: Path = Path.home(),  # path objects are provided a file picker\n",
    "        shape: int = 64,\n",
    "        use_visible_layers: bool = True,\n",
    "        state: CellState = list(CellState)[0],\n",
    "    ):\n",
    "        \"\"\" Export the annotations: \"\"\"\n",
    "        \n",
    "        export_data = {'shape': shape}\n",
    "        \n",
    "        # find the visible image layers and export the metadata\n",
    "        image_layers = [layer for layer in viewer.layers if isinstance(layer, Image)]\n",
    "        for layer in image_layers:\n",
    "            if use_visible_layers and layer.visible:\n",
    "                export_data[layer.name] = layer.metadata\n",
    "        \n",
    "        # record the coordinates of the annotations \n",
    "        for idx in range(points_layer.data.shape[1]):\n",
    "            export_data[f'coords-{idx}'] = points_layer.data[:, idx].tolist()\n",
    "        \n",
    "        # record the state labels of the annotations \n",
    "        export_data['labels'] = points_layer.properties['State'].tolist()\n",
    "        \n",
    "        # TODO: say whether patch is flagged or not:\n",
    "        export_data['flagged'] = [False for _ in points_layer.properties['State']]\n",
    "        \n",
    "        # serialize the CellState labels\n",
    "        export_data['states'] = {s.name: s.value for s in CellState}\n",
    "        \n",
    "        # extract the image patches here\n",
    "        with ZipFile(f\"../data/{SESSION_NAME}.zip\", 'w') as myzip:\n",
    "            for idx, patch_coords in enumerate(points_layer.data):\n",
    "                \n",
    "                patch_label = points_layer.properties['State'][idx]\n",
    "\n",
    "                # grab the image patch\n",
    "                image_patches, flagged = get_image_patch(image_layers, patch_coords, shape=shape)\n",
    "                \n",
    "                # check if the item was flagged:\n",
    "                export_data['flagged'][idx] = flagged\n",
    "                suffix = '_flagged' if flagged else ''\n",
    "                image_patch_fn = f\"{patch_label}/{patch_label}_{SESSION_TIME}_{idx}{suffix}.tif\"\n",
    "                \n",
    "                # open a stream to write to the zip file\n",
    "                stream = io.BytesIO()\n",
    "                imsave(stream, image_patches, format='tif')\n",
    "                stream_data = stream.getvalue()\n",
    "                myzip.writestr(image_patch_fn, stream_data)\n",
    "        \n",
    "            # write out the json log to the zip file also\n",
    "            stream = json.dumps(export_data, indent=2)\n",
    "            myzip.writestr(f\"{SESSION_NAME}.json\", stream)\n",
    "        \n",
    "        print (f\"JSON file & image patches have been exported.\\n'../data/{SESSION_NAME}.zip'\")\n",
    "        \n",
    "        return locals().values()\n",
    "    \n",
    "    def _change_points_properties(event):\n",
    "        \"\"\" Update the current properties of the points layer to reflect the currently selected state. \"\"\"\n",
    "        points_layer.current_properties['State'] = np.array([cnn_annotation_widget.state.value.name])\n",
    "    \n",
    "    cnn_annotation_widget.state.changed.connect(_change_points_properties)\n",
    "    \n",
    "    # add the magicgui dock widget \n",
    "    viewer.window.add_dock_widget(cnn_annotation_widget)\n",
    "    \n",
    "    @viewer.bind_key('.')\n",
    "    def next_label(event=None):\n",
    "        \"\"\" Increment the label in the GUI \"\"\"\n",
    "        new_state = (cnn_annotation_widget.state.value.value + 1) % len(CellState)\n",
    "        cnn_annotation_widget.state.value = CellState(new_state)\n",
    "        \n",
    "    @viewer.bind_key(',')\n",
    "    def previous_label(event=None):\n",
    "        \"\"\" Decrement the label in the GUI \"\"\"\n",
    "        new_state = (cnn_annotation_widget.state.value.value - 1) % len(CellState)\n",
    "        cnn_annotation_widget.state.value = CellState(new_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the cell below will open *napari* in a separate Python window. \n",
    "\n",
    "*Note:* ***Please allow a few seconds for the GUI to load.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file & image patches have been exported.\n",
      "'../data/annotation_03-16-2021--10-58-50.zip'\n"
     ]
    }
   ],
   "source": [
    "with napari.gui_qt():\n",
    "    \n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(data, name='GFP', metadata=metadata)\n",
    "   \n",
    "    annotator(viewer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the annotations:\n",
    "\n",
    "1. Click on the ```Export``` button at the bottom right corner of the *napari* window when done annotating.\n",
    "2. The name of the exported file will be printed under the cell above. Please check it was saved successfully in the folder.\n",
    "3. Close the *napari* window & quit the python GUI completely.\n",
    "\n",
    "(Doing so will cause this notebook's kernel to die. This outcome is fine as this notebook task is finished.)\n",
    "\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "1. If you prefer to check the quality of your image patches and visualise some of your overall data statistics, please visit the **B_CNN_Data_Preview_Images.ipynb** iPython notebook\n",
    "2. If you'd like to proceed directly to the neural network training step in the Google Colab environment, please visit the **C_CNN_Training_and_Validation.ipynb** iPython notebook\n",
    "\n",
    "\n",
    "#### Done! You can close this notebook now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
